\documentclass[review]{elsarticle}

\usepackage{lineno,hyperref}
\modulolinenumbers[5]

\journal{Journal of \LaTeX\ Templates}
\usepackage{amssymb}
\usepackage{amsmath,amsthm}
\usepackage{float}
\usepackage{url}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{todonotes}
\usepackage{amsthm} 
\usepackage[ruled,vlined,linesnumbered]{algorithm2e} 
\usepackage{makecell}


\onehalfspacing
\usepackage{pdfpages}
\usepackage{times}
\usepackage{multirow}
\usepackage[toc,page]{appendix}
\usepackage{listings}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\newtheorem{example}{Example}
\newtheorem{proposition}{Proposition}


\DeclareMathOperator{\supp}{support}
\DeclareMathOperator{\support}{support}
\DeclareMathOperator{\Trim}{Trim}
\DeclareMathOperator{\LTrim}{LTrim}

\begin{document}

\begin{definition}\label{consecutive} For a set $S \subseteq \mathbb{R}$ we say that
$B \subseteq S$ is \emph{consecutive} if any $s\in S$ that is smaller than $\max(B)$ and larger than $\min(B)$ is in $B$.
\end{definition}

\begin{definition}\label{part_consecutive} A partition $P=\{B_1,\dots,B_n\}$ of a set $S \subseteq \mathbb{R}$ is called 
\emph{consecutive} if all the subsets $B_1 ,\dots,B_n$ are consecutive.
\end{definition}


\begin{definition}\label{partition}
	For a discrete real random variable $X$ and a partition $P$ of its support, we define a new discrete random variable $X_P$ by:
	
	$$Pr(X_P = t) = \begin{cases} 
	Pr(X\in B) &  \text{if } t = min(B) \wedge  B \in P, \\
	0      & \text{otherwise.}
	\end{cases}$$
\end{definition}


\begin{definition}
	For discrete real-valued variables $X_1$ and $X_2$, we say that $X_2$ is a one-sided Kolmogorov approximation of $X_1$ with the parameters $\varepsilon$ and $m$, denoted by 
	$X_1 \preceq_{\varepsilon,m} X_2$, if $\forall t\colon 0 \leq   F_{X_2}(t)-F_{X_1}(t) \leq \varepsilon$ and $|\support(X_2)| \leq m$. 
	%We say that the approximation is \textbf{tight} if there exists no  $X_2' \neq X_2$ such that $X_1 \preceq_{\varepsilon,m} X_2'$ and, $\forall t$, $F_{X_2'}(t) \leq F_{X_2}(t)$. 
\end{definition}

\begin{definition}
	For a discrete real-valued random variable $X$ and $m \in \mathbb{N}$, 
	let $\varepsilon^* = \min\{\varepsilon \colon \text{  there is $X'$ such that $X \preceq_{\varepsilon,m} X'$}\}$ be the best possible approximation error for $X$ with a random variable whose support of size $m$. 
\end{definition}


% Gera: The following is actually true for every \varepsilon, not only for \varepsilon^*.

\begin{theorem}\label{approxAsPart}
For any discrete real-valued random variable $X$ and any $m \in \mathbb{N}$, there is consecutive partition $P$ of $\supp(X)$ such that $X \preceq_{\varepsilon^*,m} X_P$.
\end{theorem}

\begin{proof}
Let $X'$ be such that $X \preceq_{\varepsilon^*,m} X'$. Specifically, for all $t$,
\begin{equation}
F_{X}(t) \leq F_{X'}(T) \leq F_X(t)+\varepsilon^*
\label{*}
\end{equation}
The proof has two steps of constructions:$1) X'\Rightarrow X''; 2) X''\Rightarrow X'''$.

Assume that $t_0,t_1,\dots,t_n$ are all the elements in the support of $X$ in ascending order. Define the random variable $X''$ by 
$$
Pr(X''=t) = \begin{cases}
Pr(X' \leq t_0)           & \text{if } t=t_0  \\ 
Pr(t_{i-1} < X' \leq t_i) & \text{if } t=t_i \text{ for some } i \neq 0 \\ 
0                         & \text{otherwise}
\end{cases}
$$

We will show now that: (1) $\support(X'') \subseteq \support(X)$; (2) $X \preceq_{\varepsilon,m} X'''$.
Only a non-zero probability can be assigned to $Pr(X''=t)$, if $t \in \support(X)$, then $\support(X'') \subseteq \support(X)$. Furthermore, by construction of $X''$, $|\support(X'')|\leq m$ since $|\support(X')|\leq m$ and every $ t\in \support(X')$ is mapped to a value in $\support(X)$ then $|\support(X'')|\leq |\support(X')|$

In addition, we will show now that $F_{X}(t) \leq  F_{X''}(t) \leq F_{X'}(t)$ for all $t$ by examine the different $t$s as follows: 
\begin{description}
\item[Case $t < t_0$:] $F_{X''}(t)=F_{X}(t)=0$. Since $F_{X'}(t) \geq 0$ for all $t$, we get that $F_{X}(t) \leq  F_{X''}(t) \leq F_{X'}(t)$.
\item[Case $t=t_i$:] $F_{X'}(t)=F_{X''}(t)$ and $F_{X}(t) \leq F_{X'}(t)$ by Eq. \eqref{*}.
\item[Case $t_{i-1} < t < t_i$:]
$F_{X}(t) \leq F_{X''}(t) \leq F_{X'}(t)$ from Claim~\ref{suppGMin}
% $F_{X''}(t)= F_{X''}(t_{i-1})$ and $F_{X}(t)=F_{X}(t_{i-1})$. Since we already have that $F_{X}(t_{i-1}) \leq F_{X''}(t_{i-1}) \leq F_{X'}(t_{i-1})$, we get that $F_{X}(t) \leq F_{X''}(t) \leq F_{X'}(t_{i-1})$. By monotonicity of CDF, $F_{X'}(t_{i-1}) \leq F_{X'}(t)$ therefore $F_{X}(t) \leq F_{X''}(t) \leq F_{X'}(t)$.
\item[Case $t > t_n$:] $F_{X}(t)= F_{X''}(t)=1$ and, by Eq.~\eqref{*}, since CDFs are always smaller or equal to one, also $F_{X'}(t)=1$.

\end{description}
From the four different cases of $t$ and that $\supp(X'')\leq m$ we established that $X \preceq_{\varepsilon,m} X''$. 

Let $s_0,s_1,\dots,s_m$ be the elements in the support of $X''$ in ascending order. Define the random variable $X'''$
$$
Pr(X'''=t) = \begin{cases}
Pr(s_{i} \leq X < s_{i+1}) & \text{if } t=s_i \text{ for some } i > m \\ 
Pr(X \geq s_m)           & \text{if } t=s_m  \\ 
0                        & \text{otherwise}
\end{cases}
$$
We will show that: (1)$X \preceq_{\varepsilon,m} X'''$; (2) There is a partition $P$ such that $X'''=X_P$. 
Again, we will show that $F_{X}(t) \leq  F_{X'''}(t) \leq F_{X''}(t)$ for all $t$ by examine the different values of $t$ as follows: 
\begin{description}
\item[Case $t < s_0$:] $F_{X'''}(t)=F_{X''}(t)=F_{X}(t)=0$. 
\item[Case $t=s_i$:] First $F_{X}(t) \leq F_{X'''}(t)$ since $F_{X}(t) \leq F_{X}(t)+Pr(s_{i} < X < s_{i+1})$ 
and second $F_{X'''}(t) \leq F_{X''}(t)$  from Claim~\ref{partGMin}. Therefore $F_{X}(t) \leq F_{X'''}(t) \leq F_{X''}(t)$.
\item[Case $s_{i-1} < t < s_i$:] $F_{X''}(t)= F_{X''}(t_{i-1})$, $F_{X}(t)=F_{X}(t_{i-1})$, and $F_{X'''}(t)= F_{X'''}(t_{i-1})$. Therefore $F_{X}(t) \leq F_{X'''}(t) \leq F_{X''}(t)$.  
\item[Case $t > s_n$:] $F_{X}(t)= F_{X''}(t)=1$ and, by~\eqref{*}, since CDFs are always smaller or equal to one, also $F_{X'}(t)=1$.
\end{description}
From the four different cases of $t$ and that $\supp(X'')=\supp(X''')$ we established that $X \preceq_{\varepsilon,m} X'''$. 
The next step is prove that $X'''=X_P$, by presenting a partition $P$. As shown before, $\support(X)=\{t_0,t_1,\dots,t_n\}$,  $\support(X''')=\{s_0,s_1,\dots,s_m\}$, and concluded that $\support(X''')\subseteq \support(X)$. In addition, $\forall 0\leq i\leq m, Pr(X'''=s_i) = Pr(s_i \leq X \leq s_{i+1})=\sum^{s_{i+1}}_{t=s_i} Pr(X=t)$ therefore $P = \{s_0,s_1,\dots,s_m\}$.
By definition~\ref{partition}, $X'''=X_P$, moreover, by definition~\ref{part_consecutive} $P$ is a consecutive partition.
\end{proof}
\begin{claim}\label{suppGMin}
If $t_{i-1} < t < t_i$ then $F_{X}(t) \leq F_{X''}(t) \leq F_{X'}(t)$
\end{claim}
\begin{proof}
$F_{X''}(t)= F_{X''}(t_{i-1})$ and $F_{X}(t)=F_{X}(t_{i-1})$. Since we already have that $F_{X}(t_{i-1}) \leq F_{X''}(t_{i-1}) \leq F_{X'}(t_{i-1})$, we get that $F_{X}(t) \leq F_{X''}(t) \leq F_{X'}(t_{i-1})$. By monotonicity of CDF, $F_{X'}(t_{i-1}) \leq F_{X'}(t)$ therefore $F_{X}(t) \leq F_{X''}(t) \leq F_{X'}(t)$.
\end{proof}

\begin{claim}\label{partGMin}
If $t=s_i$ then $F_{X'''}(t) \leq F_{X''}(t)$
\end{claim}
\begin{proof}
\begin{align*}
&Pr(X''' \leq t) \leq Pr(X''\leq t) \Rightarrow\\
&Pr(X\leq s) + Pr(s<X< s_{i+1}) \leq Pr(X\leq s) + \varepsilon \Rightarrow\\
&Pr(s<X< s_{i+1})\leq \varepsilon
\end{align*}
True from Eq.~\ref{*}

\end{proof}

\begin{algorithm}
  \DontPrintSemicolon
  \SetKwFunction{Sequence}{Sequence} 
  \SetKwFunction{Convolv}{Conv}
  \SetKwFunction{Trim}{Trim}
  \SetKwFunction{getPartition}{getPartition}
  \SetKwFunction{bellmanFordMinMaxM}{bellmanFordMinMaxM}
   $S = \support(X)\cup \{\infty\}$\;
   $L,\varepsilon$ = \getPartition($S$,$m$)\;
   \ForEach{$e=(i,j) \in  L $ }{
   $X' = append(X', (i,Pr(i\leq X<j))$
   }
   \Return $X', \varepsilon$\;
   %-------------------------------%
  \SetKwProg{myproc}{Procedure}{}{}
  \myproc{
  getPartition($S$,$m$)
  }{
   $G=(V,E)=(S,S\times S)$ \;

   \ForEach{$e=(i,j) \in  E $ }{
   $w(e) = Pr(i<X<j)$
   }
   \Return \bellmanFordMinMaxM($G$, $min(V)$, $m$)  \; }
  %-------------------------------%
  \SetKwProg{myproc}{Procedure}{}{}
  \myproc{
  bellmanFordMinMaxM($G$,$source$,$m$)
  }{$bottleneck(x) =    min   [max(bottleneck(v),w(e))]$\;
  /* Run Bellman-Ford algorithm as minimax bottleneck path version, $m$ times, starting with a single source, where $L$ is the path and $\varepsilon$ is the minimal bottleneck weight */ }
  
     
\caption{OptTrim ($X$, $m$)}  
\label{alg:sequence}
\end{algorithm}


\begin{algorithm}
	\DontPrintSemicolon
	\SetKwFunction{Sequence}{Sequence} 
	\SetKwFunction{Convolv}{Conv}
	\SetKwFunction{Trim}{Trim}
	\SetKwFunction{getPartition}{getPartition}
	\SetKwFunction{bellmanFordMinMaxM}{bellmanFordMinMaxM}
	$S = \support(X)\cup \{\infty\}$\;
	$G=(V,E)=(S, \{ (i,j) \in S^2 \colon  j>i \})$ \;
	
	\ForEach{$e=(i,j) \in  E $ }{
		$w(e) = Pr(i<X<j)$
	}

	/* The following can be obtained, e.g., using the Bellman-Ford algorithm */\;
	$l= \operatorname{argmin}\limits_{l \in paths(G),|l|=m}  \max \{ w(e)\colon e \in l  \}$ \;
	
	\ForEach{$e=(i,j) \in  l $ }{
		$f_{X'}(i) = Pr(i\leq X<j)$
	}

	\Return $X'$\;
	
	\caption{OptTrim ($X$, $m$)}  
	\label{alg:sequence}
\end{algorithm}


\begin{theorem}
$X \preceq_{\varepsilon^*,m} OptTrim(X,m)$.
\end{theorem}

\begin{proof}
As proved in Theorem~\ref{approxAsPart} there is a consecutive partition $P$ for which $X \preceq_{\varepsilon^*,m} X_P$. In order to obtain this partition we use an idea similar to the one presented in~\cite{chakravarty1982partitioning}. Construct a complete graph $G$ where each of the nodes $V$ represented by the support of $X$. The weight $w$ of each edge $(i,j)\in E$, determine by $w =F_X(j-1)-F_X(i)=Pr(i<X<j)$ the probability of $X$ to get a value between $i,j$ non inclusive. Then, find the $m$ edges path which contains the lightest bottleneck. This can be achieved by using the $Bellman-Ford$ algorithm with two tweaks: The first, iterate the graph $G$ only $m$ times, the second, fined lightest bottleneck and not shortest path by "relaxing" in the following manner $bottleneck(x) =    min   [max(bottleneck(v),w(e))]$. Form the resulted path, it is easy to derive the $X_P$.
\end{proof}

%\begin{theorem}
%Given $X_1 \dots X_k$ discrete random variables in a table representation and $m \in \mathbb{N}$, if $X'=OptimalTrim(X_1 \dots X_k,m)$, a discrete random variable and a partition of $X$ with a support of size $\leq m$ then $\max\limits_{t}|F_{\sum_1^k X_i}(t)-F_{X'}(t)|$ is minimal.
%
%\end{theorem}
%
%\begin{proof}
%From Lemma~\ref{consecutive} we get that the optimal partition for the objective function $|F_{\sum_1^k X_i}(t)-F_{X'}(t)|$ is consecutive.
%Using this fact allow us to reduce our problem to the same problem solved by Rothblum in the paper from 1982. Let $X = \sum_{i=1}^k X_i$, from Rothblum we first construct the weighted graph $G = (V,E)$, where $V = \support(X), E = \{\forall i,j \in V, (i,j)\in E\}$ and the weights $\forall e=(i,j)\in E, w(e) = |F_{X}(i)-F_{X}(j)|$. In a classical Rothblum the shortest path is found by Bellman Ford algorithm, in our case we use a variation of Bellman-Ford, minimax bottleneck path by using the function $bottleneck(x) =    min   [max(bottleneck(v),w(e))]$. Bellman-Ford algorithm can be forced to return path of some length, in our case $m$, meaning, find the lightest maximal edge in a length $m$ path. 
%$X'$ is the result of $OptimalTrim(X_1 \dots X_n,m)$, which is the same as described above. 
%\end{proof}

%\begin{algorithm}
%  \DontPrintSemicolon
%  \SetKwFunction{Sequence}{Sequence} 
%  \SetKwFunction{Convolv}{Conv}
%  \SetKwFunction{Trim}{Trim}
%
%   $D=((0,1))$ //  Dummy random var.: $0$ with prob. $1$ \;
%  \For{$i=1$ \emph{\KwTo} $k$} {
%	$D$=Convolve($D, X_i$)\; 
%	}
%   $G=(E,V)$ \;
%   $V = \support(D)$\;
%   $E = \{\forall i,j \in V, (i,j)\in E\}$\;
%   \ForEach{$e=(i,j) \in  E $ }{
%   $w(e) = F_D(i)+\sum_{t=i}^j P_D(t)-F_D(i)$
%   }
%   $L, \varepsilon$=BellmanFord($G$, $min(V)$, $m$, $bottleneck(x) =    min   [max(bottleneck(v),w(e))]$) /* Run Bellman-Ford algorithm as minimax bottleneck path version, $m$ times, starting with a single source, where $L$ is the path */ \;
%   %http://www.cs.cmu.edu/afs/cs/academic/class/15451-f04/www/lectures/lect1012.txt
%   $D'=()$\;
%   \ForEach{$e=(i,j) \in  L $ }{
%   $D' = append(D', (i,\sum_{t=i}^j P_D(t))$
%   }
%   \Return $D, bottleneck(x)$\;
%  %-------------------------------%
%  \SetKwProg{myproc}{Procedure}{}{}
%  \myproc{
%  BellmanFord($G$,$source$,$m$,$f$)
%  }{ }
%     
%\caption{OptimalTrim ($X_1,\dots,X_k$ , $m$)}  
%\label{alg:sequence}
%\end{algorithm}


Two not proved yet issues:
1) why the first gives us the minimal partition? 2) bottleneck  = the maximal error, $\varepsilon$.
\end{document}

